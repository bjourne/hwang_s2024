2024-01-29 04:51:20,214 -      Spiked-Attention: [    INFO] - Test in distributed mode with multiple processes, 1 device per process.Process 3, total 4, device cuda:3.
2024-01-29 04:51:20,310 -      Spiked-Attention: [    INFO] - Test in distributed mode with multiple processes, 1 device per process.Process 1, total 4, device cuda:1.
2024-01-29 04:51:20,541 -      Spiked-Attention: [    INFO] - Test in distributed mode with multiple processes, 1 device per process.Process 2, total 4, device cuda:2.
2024-01-29 04:51:20,608 -      Spiked-Attention: [    INFO] - Test in distributed mode with multiple processes, 1 device per process.Process 0, total 4, device cuda:0.
2024-01-29 04:51:20,933 -      Spiked-Attention: [    INFO] - Model swin_tiny_patch4_window7_224 created, param count:28323682
2024-01-29 04:51:20,933 -     timm.data.config: [    INFO] - Data processing configuration for current model + dataset:
2024-01-29 04:51:20,933 -     timm.data.config: [    INFO] - 	input_size: (3, 224, 224)
2024-01-29 04:51:20,933 -     timm.data.config: [    INFO] - 	interpolation: bicubic
2024-01-29 04:51:20,933 -     timm.data.config: [    INFO] - 	mean: (0.485, 0.456, 0.406)
2024-01-29 04:51:20,933 -     timm.data.config: [    INFO] - 	std: (0.229, 0.224, 0.225)
2024-01-29 04:51:20,933 -     timm.data.config: [    INFO] - 	crop_pct: 0.9
2024-01-29 04:51:20,933 -     timm.data.config: [    INFO] - 	crop_mode: center
2024-01-29 04:51:21,012 -      Spiked-Attention: [    INFO] - AMP not enabled. Training in float32.
2024-01-29 04:51:21,183 - timm.models._helpers: [    INFO] - Restoring model state from checkpoint...
2024-01-29 04:51:21,200 - timm.models._helpers: [    INFO] - Loaded checkpoint 'model_best.pth.tar' (epoch 295)
2024-01-29 04:51:21,214 -      Spiked-Attention: [    INFO] - Using native Torch DistributedDataParallel.
2024-01-29 04:51:22,214 -      Spiked-Attention: [    INFO] - Run pre-trained Model(ANN) with searching optimal Base and Maximum(M_z)
2024-01-29 04:51:23,166 -      Spiked-Attention: [    INFO] - ANN: [   0/195]  Time: 0.945 (0.945)  Loss:   0.556 ( 0.556)  Acc@1:  90.625 ( 90.625)  Acc@5:  98.828 ( 98.828)
2024-01-29 04:51:35,995 -      Spiked-Attention: [    INFO] - ANN: [  50/195]  Time: 0.255 (0.270)  Loss:   0.554 ( 0.721)  Acc@1:  90.625 ( 85.241)  Acc@5:  98.047 ( 97.197)
2024-01-29 04:51:49,743 -      Spiked-Attention: [    INFO] - ANN: [ 100/195]  Time: 0.224 (0.272)  Loss:   1.120 ( 0.812)  Acc@1:  74.219 ( 82.987)  Acc@5:  93.750 ( 96.326)
2024-01-29 04:52:02,675 -      Spiked-Attention: [    INFO] - ANN: [ 150/195]  Time: 0.275 (0.268)  Loss:   0.857 ( 0.883)  Acc@1:  83.984 ( 81.353)  Acc@5:  95.703 ( 95.579)
2024-01-29 04:52:14,152 -      Spiked-Attention: [    INFO] - ANN: [ 195/195]  Time: 0.057 (0.265)  Loss:   1.591 ( 0.912)  Acc@1:  53.750 ( 80.646)  Acc@5:  91.250 ( 95.344)
2024-01-29 04:52:14,152 -      Spiked-Attention: [    INFO] - Pre-trained ANN Performance:  Acc@1:  80.646  Acc@5:  95.344  number of GFLOPs:   4.494  ANN Energy (mJ):  20.674  
2024-01-29 04:52:14,153 -      Spiked-Attention: [    INFO] - Searched Optimal Base: 1.16  
2024-01-29 04:52:14,193 -      Spiked-Attention: [    INFO] - Embed Spiking Neuron on each layer
2024-01-29 04:52:14,193 -      Spiked-Attention: [    INFO] - Validate Spiked-Attention: Accuracy and Energy
2024-01-29 04:52:30,252 -      Spiked-Attention: [    INFO] - SNN: [   0/195]  Time: 16.057 (16.057)  Acc@1:  89.062 ( 89.062)  Acc@5:  98.438 ( 98.438)
2024-01-29 05:04:08,651 -      Spiked-Attention: [    INFO] - SNN: [  50/195]  Time: 13.969 (14.009)  Acc@1:  90.625 ( 84.896)  Acc@5:  97.656 ( 97.005)
2024-01-29 05:15:47,146 -      Spiked-Attention: [    INFO] - SNN: [ 100/195]  Time: 13.956 (13.990)  Acc@1:  73.828 ( 82.673)  Acc@5:  93.359 ( 96.144)
2024-01-29 05:27:25,392 -      Spiked-Attention: [    INFO] - SNN: [ 150/195]  Time: 13.966 (13.981)  Acc@1:  83.984 ( 80.929)  Acc@5:  94.141 ( 95.300)
2024-01-29 05:37:47,323 -      Spiked-Attention: [    INFO] - SNN: [ 195/195]  Time: 7.744 (13.945)  Acc@1:  51.250 ( 80.150)  Acc@5:  91.250 ( 95.054)
2024-01-29 05:37:47,325 -      Spiked-Attention: [    INFO] - Converted Spiked-Attention performance:  Acc@1:  80.150  Acc@5:  95.054  Energy of SNN (mJ):   3.023  
